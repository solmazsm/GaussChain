# aussian Attack Detection in Incentive-Token-Based Federated Learning
This repository contains the implementation for detecting the Gaussian attack in incentive-token-based federated learning systems. The code supports both attack simulation and blockchain-based auditing mechanisms to ensure transparency and security in FL environments.

Contents
ğŸ“Œ Attack Simulation: Implements the Gaussian attack where colluding clients inject controlled noise to manipulate token rewards.

ğŸ” Detection Mechanism: Blockchain-based auditing protocol leveraging Merkle trees and peer verification.

ğŸ“Š Experiments & Evaluation: Scripts for running federated training with different datasets and aggregation algorithms.

ğŸ“‚ Datasets: Preprocessed versions of MNIST, Fashion-MNIST, CIFAR-10, and SVHN.

ğŸ›  Reproducibility Guide: Step-by-step instructions to replicate our experiments.

Getting Started
Clone the repository and follow the instructions in README.md to set up the environment and run the simulations.

git clone [your-repo-link]
cd [repo-name]
pip install -r requirements.txt
